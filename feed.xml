<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fenn, larry</title>
    <description>some of my research, thoughts, and projects.
</description>
    <link>http://larryfenn.com/</link>
    <atom:link href="http://larryfenn.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 14 Dec 2015 07:25:39 -0500</pubDate>
    <lastBuildDate>Mon, 14 Dec 2015 07:25:39 -0500</lastBuildDate>
    <generator>Jekyll v3.0.0</generator>
    
      <item>
        <title>Gun Violence Statistics</title>
        <description>&lt;p&gt;&lt;a href=&quot;/gva&quot;&gt;&lt;img src=&quot;/gva/post_assets/preview.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://www.gunviolencearchive.org/&quot;&gt;Gun Violence Archive&lt;/a&gt; (GVA) is a database of gun violence and gun crime in general aggregated from a diverse array of sources. The specific details of their methodology for tagging incidents is listed under their &lt;a href=&quot;http://www.gunviolencearchive.org/methodology&quot;&gt;Methodology&lt;/a&gt;.&lt;/p&gt;

&lt;!--more--&gt;

&lt;div id=&quot;toc&quot;&gt;&lt;/div&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#1&quot;&gt;Getting the Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2&quot;&gt;Analysis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3&quot;&gt;Visualization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4&quot;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#A1&quot;&gt;Appendix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;1&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;getting-the-data&quot;&gt;Getting the Data&lt;/h2&gt;
&lt;p&gt;After notifying them by e-mail of my intentions, I proceeded to build a small crawler that would index all of the incidents they have on file and dump the relevant block of HTML into a text file for later processing.&lt;/p&gt;
&lt;style type=&quot;text/css&quot;&gt;
  .gist-file
  .gist-data {max-height: 10em;}
&lt;/style&gt;

&lt;script src=&quot;https://gist.github.com/larryfenn/fccc5e675525ea6ebcc3.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;The &lt;code&gt;results.txt&lt;/code&gt; file stores all of the GVA URL indices and their respective HTML &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; elements containing incident reports. The next step is to create a parser that will read through the HTML and populate a SQLite database of incidents.&lt;/p&gt;

&lt;p&gt;Since incidents have only one location and time but potentially no limit on how many people are involved, I decided to make each entry of the database tie to an individual. Thus the parser will create entries for each person who has been involved in a gun-related incident.&lt;/p&gt;

&lt;p&gt;Of course, additional fields can be defined but the relevant lines of code have to be changed to accommodate them. This particular block of code can take a long time to run because I’m using the html5lib parser, which reads the whole document in. However, this is only a one-time cost (as future updates to the database will be only those events that have happened since we last indexed).&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/larryfenn/6db23e81328910ae8e28.js&quot;&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#toc&quot;&gt;Back to top&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;div id=&quot;2&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;analysis&quot;&gt;Analysis&lt;/h2&gt;
&lt;p&gt;Now we have a SQLite database called &lt;code&gt;gva.db&lt;/code&gt; with the table GVA in it. We can now ask it some basic questions:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/gva/post_assets/gvadb.png&quot; width=&quot;769&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With a database in hand, the door is open to all sorts of investigation. In particular, let’s explore the relationship between the individuals in the database, the event (as defined and used by the GVA), and the “outcomes”; here, I will define an outcome as the status of the individual (either perpetrator or victim) at the end of the event. The two contrasts to look at are victim/perpetrator, and male/female. The definition of “perpetrator” in this situation is not always the person using the gun; for example, someone who is shot at during an attempted home invasion will be called a “perpetrator”. Using the GVA’s notation, the possible outcomes are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Unharmed.&lt;/li&gt;
  &lt;li&gt;Injured.&lt;/li&gt;
  &lt;li&gt;Killed.&lt;/li&gt;
  &lt;li&gt;Arrested.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A simple python script can automate the access, storage, and plotting of the data:
&lt;script src=&quot;https://gist.github.com/larryfenn/df194b702fb72812347b.js&quot;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;With my treatment of the data, these are tags attached to  gun related incidents; it is not quite a direct count of factors, since a single event frequently has many tags attached to it in the GVA. However, the relative frequency of the different tags can still communicate what the nature of gun incidents and gun violence in America looks like:&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-all-perpetrators-in-the-gva&quot;&gt;Top event characteristics for all perpetrators in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/pt.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/ptl.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-all-victims-in-the-gva&quot;&gt;Top event characteristics for all victims in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/vt.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/vtl.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DGU stands for “Defensive Gun Use”. Looking at the data for all perpetrators and victims, &lt;strong&gt;Armed robbery&lt;/strong&gt; is the number one tag in use for both. On the victim side, it turns out &lt;strong&gt;Mass Shooting&lt;/strong&gt; sits just below &lt;strong&gt;Accidental Shooting&lt;/strong&gt; in terms of frequency in the GVA database.&lt;/p&gt;

&lt;p&gt;Now let’s examine the gender differences, if any (for those records where gender is filled in):&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-male-perpetrators-in-the-gva&quot;&gt;Top event characteristics for male perpetrators in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/pm.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/pml.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-female-perpetrators-in-the-gva&quot;&gt;Top event characteristics for female perpetrators in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/pf.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/pfl.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Armed robbery&lt;/strong&gt; is at roughly the same frequency for male perpetrators as for the whole database, but for female perpetrators it has fallen down from 1st to 4th most used tag, with &lt;strong&gt;Non-Shooting Incident&lt;/strong&gt; rising from 3rd to 1st most used. &lt;strong&gt;Domestic Violence&lt;/strong&gt; for male perpetrators sits between &lt;strong&gt;Defensive Use&lt;/strong&gt; and &lt;strong&gt;Car-jacking&lt;/strong&gt; at 2.16%, while for female perpetrators it sits between &lt;strong&gt;Brandishing&lt;/strong&gt; and &lt;strong&gt;ATF/LE Confiscation&lt;/strong&gt; at 5.00%. Now let’s flip the relationship and look at victims:&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-male-victims-in-the-gva&quot;&gt;Top event characteristics for male victims in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/vm.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/vml.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-female-victims-in-the-gva&quot;&gt;Top event characteristics for female victims in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/vf.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/vfl.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Flipping from perpetrator to victim we see a dramatic change: &lt;strong&gt;Domestic Violence&lt;/strong&gt; for female victims is top of the list, at 9.24% (compare that to 3.89% when we looked at all victims, and 2.74% for male victims).&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-killed-perpetrators-in-the-gva&quot;&gt;Top event characteristics for killed perpetrators in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/pk.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/pkl.png&quot; width=&quot;400&quot; height=&quot;200&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-killed-victims-in-the-gva&quot;&gt;Top event characteristics for killed victims in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/vk.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/vkl.png&quot; width=&quot;400&quot; height=&quot;250&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Lastly, looking at how deaths from gun incidents are distributed we see that &lt;strong&gt;Suicide&lt;/strong&gt; and &lt;strong&gt;Murder/Suicide&lt;/strong&gt; are both at the top of the list along with law enforcement related tags (evoking, among other things, the notion of “suicide by cop”). &lt;strong&gt;Suicide&lt;/strong&gt; and &lt;strong&gt;Domestic Violence&lt;/strong&gt; being at the top of the list for killed victims is both a disheartening but important fact to keep in mind about the frequency of these causes in gun casualties.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#toc&quot;&gt;Back to top&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;div id=&quot;3&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;visualization&quot;&gt;Visualization&lt;/h2&gt;

&lt;p&gt;The final thing to be done with the data is to make it accessible. I picked four types of event tags that figure prominently in discussions of guns and gun control to highlight:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Accidental discharge.&lt;/li&gt;
  &lt;li&gt;Use in defense.&lt;/li&gt;
  &lt;li&gt;Use by a third party “good samaritan” in defense.&lt;/li&gt;
  &lt;li&gt;Mass shootings.&lt;/li&gt;
  &lt;li&gt;Suicide.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The result of this effort is a &lt;a href=&quot;http://larryfenn.com/gva&quot;&gt;gun violence choropleth, age/gender histogram, and time series&lt;/a&gt; d3.js document. The document aims to put at one’s fingertips national and state level data and sources. From playing around some qualitative observations can be made:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Accidental gun injuries and deaths skew younger in general in a bimodal manner with one spike at 3 years and the other at 15 years.&lt;/li&gt;
  &lt;li&gt;Looking at it per-capita, there is a distinct geographic difference between states where defensive firearm injuries and deaths occur and accidental firearm injuries and deaths occur.&lt;/li&gt;
  &lt;li&gt;The time series contains many artifacts from how police reports are filed. This is an important thing to take into account if we were to attempt any sort of time series analysis to investigate if gun violence events are correlated across time.&lt;/li&gt;
  &lt;li&gt;Looking at it by the numbers, “good samaritan” events that lead to injury or death are very rare. This may be a blind spot in the GVA: since the GVA only tracks events that get reported to the police or otherwise make the news, we have no idea how many times a standoff was resolved peacefully without notice or report but &lt;em&gt;with&lt;/em&gt; a gun.&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#toc&quot;&gt;Back to top&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;div id=&quot;4&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;The chief flaw with the GVA dataset is that its tagging system works well for simple events, but becomes difficult for events involving many victims and perpetrators. For example, a naive search of events where someone is “Unharmed” still turns up entries with tags such as “Shot - Wounded/Injured” and “Shot - Dead (murder, accidental, suicide)”. In this instance, the event-centric model of the GVA makes it difficult to proceed in a person-centric model.&lt;/p&gt;

&lt;p&gt;Another flaw of the GVA database is the perennial issue of missing data fields:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Age: 51.10% of the entries have an age listed.&lt;/li&gt;
  &lt;li&gt;Relationships: 3.28% have a relationship (Friends, Family, etc.) listed.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That being said, there is still a lot of potential still in the richness of the GVA database and I have only scratched the surface:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Location tags: 95.19% of the entries (165,121 entries) have exact GPS coordinates of the event. Knowing the location this precisely opens the door to a huge amount of additional data we can use, from political to demographic content. One potential extension is to join to the database the status of CCW permits (from most permissive to most restrictive). Another idea is to try to use the regional economic data from the BEA.&lt;/li&gt;
  &lt;li&gt;Guns involved: the GVA tracks (if possible) all the guns reported in the incidents. This is useful potentially to test the hypothesis that different guns are used for primarily different purposes.&lt;/li&gt;
  &lt;li&gt;Event tags: the tags the GVA applies to all the events can probably be grouped together in sensible ways, providing extra signal about different kinds of gun violence events. Ultimately, this points the way towards developing some type of classifier for gun violence events; when people have conversations about policy it is important to clearly illustrate their impact by ignoring the “noise” of gun violence events that the policy isn’t targeting; for example, a law designed to reduce domestic violence gun incidents should not be judged for failing to reduce the number of drive-by shootings.&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#toc&quot;&gt;Back to top&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;div id=&quot;A1&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;appendix-some-extra-graphs&quot;&gt;Appendix: Some Extra Graphs&lt;/h2&gt;

&lt;h3 id=&quot;top-event-characteristics-for-unharmed-perpetrators-in-the-gva&quot;&gt;Top event characteristics for unharmed perpetrators in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/pu.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/pul.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-unharmed-victims-in-the-gva&quot;&gt;Top event characteristics for unharmed victims in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/vu.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/vul.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The notable characteristics that jump out here are &lt;strong&gt;Institution/Group/Business&lt;/strong&gt; and &lt;strong&gt;Drug involvement&lt;/strong&gt; on the perpetrator side, and &lt;strong&gt;Defensive Use&lt;/strong&gt; on the victim side- evidence that there are a substantial amount of gun incidents where the victim defensively employs a gun and walks away unharmed.&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-injured-perpetrators-in-the-gva&quot;&gt;Top event characteristics for injured perpetrators in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/pi.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/pil.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-injured-victims-in-the-gva&quot;&gt;Top event characteristics for injured victims in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/vi.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/vil.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-arrested-perpetrators-in-the-gva&quot;&gt;Top event characteristics for arrested perpetrators in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/pa.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/pal.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;top-event-characteristics-for-arrested-victims-in-the-gva&quot;&gt;Top event characteristics for arrested victims in the GVA&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/gva/post_assets/va.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/gva/post_assets/val.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#toc&quot;&gt;Back to top&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 14 Dec 2015 01:55:00 -0500</pubDate>
        <link>http://larryfenn.com/personal/2015/12/14/gva.html</link>
        <guid isPermaLink="true">http://larryfenn.com/personal/2015/12/14/gva.html</guid>
        
        <category>python</category>
        
        <category>d3js</category>
        
        <category>sql</category>
        
        
        <category>personal</category>
        
      </item>
    
      <item>
        <title>Dota 2 Drafting Part 2: Hero Pairings</title>
        <description>&lt;p&gt;&lt;a href=&quot;/personal/dota2drafts/popularitygraph.html&quot;&gt;&lt;img src=&quot;/personal/dota2drafts/popularityexample1.png&quot; hspace=&quot;20&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/personal/dota2drafts/popularitygraph.html&quot;&gt;&lt;img src=&quot;/personal/dota2drafts/popularityexample2.png&quot; hspace=&quot;20&quot; /&gt;&lt;/a&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/personal/dota2drafts/popularitygraph.html&quot;&gt;Interactive graph: Hero pair popularity.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/personal/dota2drafts/winrategraph.html&quot;&gt;Interactive graph: Hero pair winrate.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The data collected from Valve’s API contains a plethora of information about relationships between heroes, teams, and winrates. This data lends itself to the construction of graphs depicting the relationships. This has a twofold purpose:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;To assess the integrity of the collected data. If the graphs that come out don’t line up with the common strategic thinking about the heroes then additional stratification is necessary (most likely by game skill bracket).&lt;/li&gt;
  &lt;li&gt;To explore the data set to see what hero combinations are popular along with showing which combinations work well and which don’t.&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;data-processing&quot;&gt;Data Processing&lt;/h2&gt;

&lt;p&gt;Since the record for each match contains information as to which team won, and what the picks were, it’s just a matter of another MapReduce job to pull out the relationships between heroes, picks, and win rates. In particular, each game record gives us 5 heroes that won together, and 5 heroes that lost together. Thus our mapper step looks like this (after we get the picks by team):&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;radiantcliq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itertools&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;radiantpicks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;direcliq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itertools&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;direpicks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# one can edit the combinations argument to pull out arbitrary n-cliques&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;radiantcliq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;team_win&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;True&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;direcliq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;team_win&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;False&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The result of the MapReduce step is essentially a list of edges and weights. Python has the &lt;code&gt;networkx&lt;/code&gt; library which allows us to create the graph structure without much fuss; even better, it supports JSON output which allows us to use D3.js to render the graphs and play around with them.&lt;/p&gt;

&lt;h2 id=&quot;the-graphs&quot;&gt;The Graphs&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;/personal/dota2drafts/winrategraph.html&quot;&gt;&lt;img src=&quot;/personal/dota2drafts/winrateexample1.png&quot; hspace=&quot;20&quot; vspace=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Winrates necessitate special treatment. Each hero, indexed as \(i\), has their own, winrate (indexed over all heroes):&lt;/p&gt;

&lt;p&gt;\[\dfrac{W_i}{N_i} = \dfrac{\displaystyle\sum_j w_{ij}}{\displaystyle\sum_j n_{ij}}\]&lt;/p&gt;

&lt;p&gt;For a hero pair \((i, j)\) the hero pair popularity is \(n_{ij}\) and the hero pair winrate is \(\frac{w_{ij}}{n_{ij}}\). However, this hero pair winrate does not have an obvious relationship with the “absolute” winrates for the heroes, \(\frac{W_i}{N_i}\) and \(\frac{W_j}{N_j}\). The pair winrate alone is not very informative; what would be informative is a determination of &lt;i&gt;how much better&lt;/i&gt; the pair is. The simplest (although coarsest) measure is the difference between the pair winrate and the maximum of the individual winrates:&lt;/p&gt;

&lt;p&gt;\[r_{ij} = \dfrac{w_{ij}}{n_{ij}} - \max\left(\dfrac{W_i}{N_i}, \dfrac{W_j}{N_j}\right)\]&lt;/p&gt;

&lt;p&gt;This is a measure of the “improvement” the pair has to working individually.&lt;/p&gt;

&lt;h2 id=&quot;graph-topology&quot;&gt;Graph Topology&lt;/h2&gt;

&lt;p&gt;By selecting a threshold parameter and removing edges if their weights fall below the threshold, the graphs for winrates and popularity can be endowed with more interesting topology. Both of the graphs could have a quite different topology depending on the skill level of the population being drawn from. Additionally, different measures of popularity and winrate can easily give rise to different topologies depending on what is being measured. For example, a similar procedure to the winrate improvement measure could be employed on popularity to filter out the existing effect of a hero being popular; it is no surprise that Earthshaker is at the apparent center of the popularity graph since (as we saw in the previous post) he is far and away the most picked hero by himself in the data set.&lt;/p&gt;

&lt;p&gt;Ideally, we would prefer measures that give us graph topologies that give rise to many disjoint parts with as few isolated nodes as possible. These disjoint parts would line up with distinct strategies or combinations; for example, the Tiny-Io combination shows up as a disjoint element in the popularity graph already for any threshold below 4800.&lt;/p&gt;

&lt;h2 id=&quot;further-plans&quot;&gt;Further Plans&lt;/h2&gt;

&lt;p&gt;The analysis up to now has assumed that heroes perform equally well on radiant and dire side- not necessarily true. Additionally, it has made no distinction in skill groups; all of the analysis has been done on the total data from all the public matches.&lt;/p&gt;

&lt;p&gt;Alternative graphs and measures could be used to determine more information. One relationship that may be worth exploring is a “counter-pick” graph that tracks how many times two heroes faced off against each other on separate teams. Another graph worth looking into could be the “anti-pair” graph working to distinguish which heroes fulfill a similar role: if we count up how many times a hero is &lt;i&gt;not&lt;/i&gt; picked when another hero is picked. However, there will be a significant amount of noise since any particular game only allows for 5 picks, leaving 95% of the hero pool unpicked as a matter of course.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/personal/dota2drafts/popularitygraph.html&quot;&gt;Hero pair popularity graph&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/personal/dota2drafts/winrategraph.html&quot;&gt;Hero pair winrate graph&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 13 Nov 2015 18:55:02 -0500</pubDate>
        <link>http://larryfenn.com/personal/2015/11/13/dota2drafts2.html</link>
        <guid isPermaLink="true">http://larryfenn.com/personal/2015/11/13/dota2drafts2.html</guid>
        
        <category>python</category>
        
        <category>hadoop</category>
        
        <category>d3js</category>
        
        <category>dota2</category>
        
        
        <category>personal</category>
        
      </item>
    
      <item>
        <title>Dota 2 Drafting Part 1: Data Collection</title>
        <description>&lt;p&gt;Dota 2 captain’s mode entails a drafting phase where a sequence of picks and bans are issued by the team captains. As of this writing, there have been 1,933,725,512 total matches of Dota 2 played, in all modes. It may be possible now with this body of data to build a machine learning algorithm for prediction and for drafting suggestions.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;getting-the-data&quot;&gt;Getting the data&lt;/h2&gt;

&lt;p&gt;The web API for Dota 2 has two functions we can use to grab match data as a JSON object from some index. The first, &lt;code&gt;GetMatchHistory&lt;/code&gt;, has a game mode argument and date argument which would make it ideal for stratifying the data by patch release. However, it has three flaws that preclude its use:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It is capped (for some reason, most likely a bug judging from all the angry dev forum posts) at grabbing the most recent 500 games.&lt;/li&gt;
  &lt;li&gt;It does not return the pick/ban record, only the game type of a match.&lt;/li&gt;
  &lt;li&gt;The game mode argument currently does not work (lol Valve).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The second function, &lt;code&gt;GetMatchHistoryBySequenceNum&lt;/code&gt;, does return the pick/ban record and does not have any limitation on how far it can reach, but it does not support any date parameters. Thus, determining the actual patch number a match was played in will necessitate going into the records and accessing the UNIX time that the match was played at. The other complication &lt;code&gt;GetMatchHistoryBySequenceNum&lt;/code&gt; has is that the sequence numbers do not directly map to the order in which matches were played- I suspect that the sequence number is issued to a match once it has finished being indexed and processed into the Dota 2 database. In other words, it is no guarantee if the sequence number for match A is higher than the sequence number for match B that match A was played after match B.&lt;/p&gt;

&lt;p&gt;The typical output from the &lt;code&gt;GetMatchHistoryBySequenceNum&lt;/code&gt; call (for a captain’s mode match) looks like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;quot;result&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&amp;quot;status&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// success code&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&amp;quot;matches&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&amp;quot;players&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;// omitted: player ids and statistics such as gold earned&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&amp;quot;radiant_win&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&amp;quot;duration&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2333&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// our metric for how hard a team won the game&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&amp;quot;start_time&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1447002472&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&amp;quot;match_id&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1923658257&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&amp;quot;match_seq_num&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1700000293&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;// omitted: other game data not relevant to us&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&amp;quot;picks_bans&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&amp;quot;is_pick&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&amp;quot;hero_id&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&amp;quot;team&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 0: radiant, 1: dire&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&amp;quot;order&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&amp;quot;is_pick&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&amp;quot;hero_id&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;85&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&amp;quot;team&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&amp;quot;order&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;// etc. for the rest of the pick/ban records&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;// ... and so on for 99 more matches&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Since we only want to index captain’s mode matches, it suffices to check if the &lt;code&gt;picks_bans&lt;/code&gt; key exists, and parse the serialized JSON into a csv for future use if it is.&lt;/p&gt;

&lt;h2 id=&quot;basic-observation-hero-popularity&quot;&gt;Basic observation: Hero popularity&lt;/h2&gt;

&lt;p&gt;One simple question we can address right now is popularity: which heroes are the most frequently banned or picked? Even better, the ordered nature of the records allows us to distinguish which heroes are frequent first bans or picks. There are two teams, each getting five picks and five bans in some sequence (i.e. there are ten picks and ten bans total per game). After trimming the column headings from the csv, a simple Hadoop MapReduce task accumulates the frequencies for all hero picks and bans by when they occur.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&quot;/personal/dota2drafts/figure_2.png&quot; width=&quot;800&quot; height=&quot;600&quot; /&gt;
    &lt;figcaption&gt;Figure 1: Picks (red) and bans (blue) with phase (1-10) represented by bar stack. A lot of heroes are higher priority bans than picks. Some heroes are much more represented in later phases: Anti-Mage, Gyrocopter, TA.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Parsing the MapReduce results into a pandas dataframe, I chose to graph the heroes that were most frequently banned/picked in total, with a stacked bar plot showing which phase the bans/picks come in on. This communicates which heroes are popular first picks or bans, i.e. heroes crucial to a team’s strategy succeeding (in the case of bans) or heroes that are particularly strong in the metagame (in the case of picks). Similarly, the timing of a pick or ban has implications; without diving too deep into the strategy of the game, hero drafting revolves around two primary goals:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Identify an opponents strategy and curtail its effectiveness with the correct selection of one’s own picks and bans.&lt;/li&gt;
  &lt;li&gt;Implementing your own strategy based on picks while limiting the opponent’s ability to address it with proper bans.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Of course, the strategy is much deeper and as of this writing still mostly unexplored space. Part of this project is to discern what features lead to a successful drafting phase.&lt;/p&gt;

&lt;h2 id=&quot;future-plans&quot;&gt;Future plans&lt;/h2&gt;

&lt;p&gt;At this point, I have indexed 80 million Dota 2 matches, roughly 500,000 of which are captain’s mode matches. This is a sufficiently large data set to begin mining for insights; there are many possible directions we can go. Currently I have a cluster of Amazon EC2 instances with Hadoop setup and ready to go, and I’ll be poking around the data set for the more ‘obvious’ statistical features while I wait for more data points to accumulate.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/personal/dota2drafts/capmodedata.zip&quot;&gt;The data set (csv (zipped), 131 MB, 461,050 games)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/larryfenn/dota2drafts&quot;&gt;https://github.com/larryfenn/dota2drafts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 13 Nov 2015 18:55:02 -0500</pubDate>
        <link>http://larryfenn.com/personal/2015/11/13/dota2drafts.html</link>
        <guid isPermaLink="true">http://larryfenn.com/personal/2015/11/13/dota2drafts.html</guid>
        
        <category>python</category>
        
        <category>pandas</category>
        
        <category>hadoop</category>
        
        <category>statistics</category>
        
        <category>dota2</category>
        
        
        <category>personal</category>
        
      </item>
    
      <item>
        <title>Centrality &amp; Maximal Entropy Random Walks</title>
        <description>&lt;p&gt;Node centrality can be tricky to measure if it is not assumed the whole graph structure is accessible. However, approximation techniques can be used (in particular, an approximation to maximal entropy random walks) to determine central nodes.&lt;/p&gt;

&lt;h1&gt;Centrality&lt;/h1&gt;
&lt;p&gt;One of the definitions of centrality for a graph is eigenvalue centrality. Eigenvalue centrality is useful in that it takes into account the centrality of neighbors (and, recursively, neighbors of neighbors and so on). Solving the eigenvalue problem for a graph adjacency matrix is best done numerically. Once finished, every node in the graph receives an appropriate centrality score.&lt;/p&gt;

&lt;p&gt;However, it may be that the structure of the whole graph is not available all at once. For example, consider the social network of friends as defined on all people- obtaining the structure of this graph requires interviewing every person on Earth and asking them to list their friends out. If we permit the existence of local information (for example, the results of interviewing one person), then it may be possible to determine approximate notions of centrality.&lt;/p&gt;

&lt;p&gt;In the case of degree centrality this is easy and uninteresting: each person’s score is simply the number of people they know. However, it turns out more sophisticated notions of centrality can also be&lt;/p&gt;

&lt;h1&gt;Random Walks&lt;/h1&gt;
&lt;p&gt;The idea is to employ random walks that have high probabilities of being in more central nodes. Random walks on graphs are defined by the probability of travelling along edges conditioned on the current location of the walker. The maximal entropy random walk is essentially the random walk given by uniformly choosing at random a direction &lt;i&gt;among all possible paths in the graph that go through that edge&lt;/i&gt; (contrast this with the uniform random walk, which chooses each edge uniformly at random).&lt;/p&gt;

&lt;p&gt;But wait! Isn’t it the case that one would need the global structure of the graph in order to determine the space of “all possible graphs through an edge”? This is in fact the case; however, an approximation to the maximal entropy random walk is possible to define up to an order which represents neighbor distance; for example, using an order 2 approximation to the random walk in the social network problem would consist in interviewing all people with a degree of separation equal to 2 from the current person.&lt;/p&gt;

&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;A lot of these subjects were really cool to investigate. Eigenvalue centrality (and other more exotic notions of centrality based on it) introduced me to spectral graph theory, which is a fascinating subject on its own; but better yet, my existing love for numerical analysis, linear algebra, and approximation algorithms blends perfectly with spectral graph theory because all-too often the underlying graph is simply too large for any other technique to work (for example, links between webpages).&lt;/p&gt;

&lt;p&gt;In a similar vein, random walks (and maximal entropy random walks in particular) fall almost exactly into the same niche, except with probability theory thrown in. Once again, approximation is necessary.&lt;/p&gt;

&lt;h1&gt;Files&lt;/h1&gt;
&lt;p&gt;For those interested in proofs and pretty diagrams, I have written up a more rigorous and detailed treatment on the subject.&lt;br /&gt;
&lt;a href=&quot;/personal/merw/text.pdf&quot;&gt;PDF&lt;/a&gt;&lt;br /&gt;
I have also given presentations about this exact topic; here is the slide deck I use.&lt;br /&gt;
&lt;a href=&quot;/personal/merw/presentation.pdf&quot;&gt;Slides&lt;/a&gt;&lt;br /&gt;
The implementation and diagrams are from the following Mathematica files.&lt;br /&gt;
&lt;a href=&quot;/personal/merw/graphs.nb&quot;&gt;Notebook 1&lt;/a&gt;, &lt;a href=&quot;/personal/merw/graphs2.nb&quot;&gt;Notebook 2&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 11 Nov 2015 17:12:00 -0500</pubDate>
        <link>http://larryfenn.com/personal/2015/11/11/merw.html</link>
        <guid isPermaLink="true">http://larryfenn.com/personal/2015/11/11/merw.html</guid>
        
        <category>graph-theory</category>
        
        <category>probability</category>
        
        <category>mathematica</category>
        
        
        <category>personal</category>
        
      </item>
    
      <item>
        <title>Assorted Academic Writing</title>
        <description>&lt;p&gt;This is an archive of expository papers I have written. I have attempted to organize them by most relevant subject area.
&lt;!--more--&gt;&lt;/p&gt;
&lt;h1&gt;Algebra&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;/assets/writing/unityhoms.pdf&quot;&gt;The existence of an injective homomorphism between \(\text{Hom}\left(\dfrac{\mathbb{Q}\lvert\zeta\rvert}{\mathbb{Q}}\right)\) and the multiplicative group \(R_n\) where \(\{x\in R_n\colon \gcd(x, n) = 1\}\)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/writing/miscalg.pdf&quot;&gt;The group of rigid motions of the cube is isomorphic to \(S_4\), and some group actions from a group to itself.&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Linear Algebra&lt;/h1&gt;
&lt;p&gt;A series of notes I typed up for the benefit of a student over the course of a spring linear algebra class.&lt;br /&gt;
&lt;a href=&quot;/assets/writing/linalgnotes/notes.pdf&quot;&gt;Part 1: Definitions, Zorn’s Lemma&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/writing/linalgnotes/notes2.pdf&quot;&gt;Part 2: Representation, Products, Duals&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/writing/linalgnotes/notes3.pdf&quot;&gt;Part 3: Infinite Product/Sum Isomorphism, Riesz&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/writing/linalgnotes/notes4.pdf&quot;&gt;Part 4: Tensor Products&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/writing/linalgnotes/notes5.pdf&quot;&gt;Part 5: Exterior Products&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/writing/linalgnotes/notes6.pdf&quot;&gt;Part 6: Determinants&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;Numerical Analysis&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;/assets/writing/numanalysis/cranknicolson.pdf&quot;&gt;Crank-Nicolson notes&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;
A series of notes I typed up for the benefit of a student over the course of a fall numerical analysis class.&lt;br /&gt;
&lt;a href=&quot;/assets/writing/numanalysis/notes1.pdf&quot;&gt;Part 1: Function Spaces&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/writing/numanalysis/notes2.pdf&quot;&gt;Part 2: Multi-Index, Fourier Transform&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/writing/numanalysis/notes3.pdf&quot;&gt;Part 3: Stability, DFT, Lax Equivalence&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/writing/numanalysis/notes4.pdf&quot;&gt;Part 4: Lax-Richtmyer Theorem&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/writing/numanalysis/notes5.pdf&quot;&gt;Part 5: Elliptical PDEs, FEM&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1&gt;Real Analysis/Measure Theory&lt;/h1&gt;
&lt;p&gt;Proofs of the following:&lt;br /&gt;
1. Integrability of \( f\) on \(\mathbb{R}\) does not necessarily imply the convergence of \(f(x)\) to \(0\) as \(x\to\infty\)&lt;br /&gt;
2. If \( f\) is integrable on \(\mathbb{R}\), then \(F(x) = \displaystyle\int_{-\infty}^x f(t)\ dt\) is uniformly continuous.&lt;br /&gt;
3. Chebyshev’s Inequality&lt;br /&gt;
4. \(f\) real-valued and integrable on \(\mathbb{R}^d\) and \(\displaystyle\int_E f(x)\ dx\geq 0\) for every measurable \(E\) implies \(f(x) \geq 0\) a.e.&lt;br /&gt;
5. A function can be integrable yet unbounded in any interval.&lt;br /&gt;
&lt;a href=&quot;/assets/writing/ra.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;Quantum Mechanics&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;/assets/writing/qm.pdf&quot;&gt;Bell’s Inequality discussion.&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 10 Nov 2015 02:05:00 -0500</pubDate>
        <link>http://larryfenn.com/personal/2015/11/10/assorted-papers.html</link>
        <guid isPermaLink="true">http://larryfenn.com/personal/2015/11/10/assorted-papers.html</guid>
        
        <category>archive</category>
        
        <category>algebra</category>
        
        <category>linear-algebra</category>
        
        <category>numerical-analysis</category>
        
        <category>real-analysis</category>
        
        <category>quantum-mechanics</category>
        
        
        <category>personal</category>
        
      </item>
    
      <item>
        <title>Mathematica Projects</title>
        <description>&lt;p&gt;This is the archive listing of all the old Mathematica projects hosted on the old website.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/personal/airfoil/airfoil.nb&quot;&gt;Dynamic airfoil flow solver.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/personal/blackscholes/collocation.nb&quot;&gt;Black-Scholes option pricing implementation via collocation.&lt;/a&gt;&lt;/p&gt;

&lt;iframe width=&quot;420&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/V2bwRxtws9w&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href=&quot;/personal/fdm/&quot;&gt;FDM: 3D heat equation, 2D wave equation, cell diffusion.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/personal/fem/fem.nb&quot;&gt;FEM obstructed channel flow solution.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/personal/fem/helmholtz.nb&quot;&gt;FEM 2D Helmholtz equation solution.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/personal/interpolation/&quot;&gt;Interpolation to arbitrary degree.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/personal/minima/&quot;&gt;Deterministic optimization: gradient search and Newton’s method.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/personal/newton/newtonvbisect.nb&quot;&gt;Bisection&lt;/a&gt;, &lt;a href=&quot;/personal/newton/newtonvsecant.nb&quot;&gt;secant method comparisons.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/personal/rm/exerciseresistance.nb&quot;&gt;Fixed stepsize&lt;/a&gt;, &lt;a href=&quot;/personal/rm/exerciseresistancedynamic.nb&quot;&gt;dynamic stepsize RM optimization.&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 09 Nov 2015 16:00:00 -0500</pubDate>
        <link>http://larryfenn.com/personal/2015/11/09/mathematica.html</link>
        <guid isPermaLink="true">http://larryfenn.com/personal/2015/11/09/mathematica.html</guid>
        
        <category>archive</category>
        
        <category>mathematica</category>
        
        
        <category>personal</category>
        
      </item>
    
      <item>
        <title>Mixed Procedures For Stochastic Optimization</title>
        <description>&lt;p&gt;This is a significant generalization of my earlier stochastic optimization efforts. I presented as an author at the INFORMS 2015 Annual Conference in Philadelphia.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/research/INFORMS2015.pdf&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A big part of the generalization was defining a more abstract setting for the problem. In a nutshell, this work concentrates on two things:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Using interval estimation to provide confidence levels and error tolerances.&lt;/li&gt;
  &lt;li&gt;Attempting to optimize over continuous and discrete domains.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Some of the notes created during the research process for both deterministic and stochastic cases: &lt;a href=&quot;/research/stopt2notes1.pdf&quot;&gt;PDF1&lt;/a&gt;, &lt;a href=&quot;/research/stopt2notes2.pdf&quot;&gt;PDF2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The experimental results from the presentation were generated and processed in Python before using Mathematica to render the graphs.&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;/research/epsilonalphasample.png&quot; width=&quot;576&quot; height=&quot;367&quot; /&gt;
	&lt;figcaption&gt;Figure 1: Samples required as a function of both confidence level (\\(\alpha\\)) and tolerance.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;/research/noisy.py&quot;&gt;Code&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is an ongoing work, so expect to see another post about this before 2016!&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Nov 2015 10:02:14 -0500</pubDate>
        <link>http://larryfenn.com/research/2015/11/04/stochastic-optimization2.html</link>
        <guid isPermaLink="true">http://larryfenn.com/research/2015/11/04/stochastic-optimization2.html</guid>
        
        <category>stochastic-optimization</category>
        
        <category>optimization</category>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Decision Trees For Survey Construction</title>
        <description>&lt;p&gt;This is a companion piece to a piece of research currently being done by Christina Zamfirescu of Hunter College about automated survey construction. As cited in the Electronic Journal of Statistics: Electron. J. Statist. 9 (2015), no. 2, 2202–2254. doi:10.1214/15-EJS1067.&lt;/p&gt;

&lt;p&gt;The article covers a few examples and transformations in parallel with her work which uses a different method.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/decisiontrees.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 22 Jul 2015 02:02:03 -0400</pubDate>
        <link>http://larryfenn.com/research/2015/07/22/decision-trees.html</link>
        <guid isPermaLink="true">http://larryfenn.com/research/2015/07/22/decision-trees.html</guid>
        
        <category>decision-trees</category>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Stochastic Optimization</title>
        <description>&lt;p&gt;Research done through Felisa Vazquez-Abad at Hunter College on stochastic optimization algorithms to solve a particular transit problem. Based off work presented at the INFORMS 2013 Winter Simulation Conference.&lt;/p&gt;

&lt;p&gt;Her original problem came by way of the Melbourne airport, which was seeking to implement a bus system to connect long-term parking lots with the airport terminals.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/research/stopt.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;Problem&lt;/h1&gt;
&lt;p&gt;The problem is a constrained optimization problem, where the constraint is rather tricky mathematically(although standard for industry and policy): 95% of passengers should not have to wait more than 10 minutes. The problem domain is on number of buses, and a control variable dictating the headway between buses.&lt;/p&gt;
&lt;h1&gt;Modeling&lt;/h1&gt;
&lt;p&gt;Modeling proceeded with one unique twist: by assuming buses were not allowed to pass each other, it is possible to use a Markov process on the sample paths for separate buses (rather than on separate instances of time). This allows for simulation to be sped up enormously, since the simulation no longer needs to simulate individual timesteps. As an additional boon, it was proven that this model supports unbiased IPA estimators for derivatives, allowing an implementation of gradient search that is much more efficient than FDM gradient search.&lt;/p&gt;
&lt;h1&gt;Further Work&lt;/h1&gt;
&lt;p&gt;The direction I am taking this in the future is to generalize where the techniques used in solving this problem are applicable. Of particular curiosity is if it can be generalized in a way that makes it applicable to something like the bike-sharing program now seen in many cities.&lt;/p&gt;
</description>
        <pubDate>Tue, 30 Dec 2014 01:02:03 -0500</pubDate>
        <link>http://larryfenn.com/research/2014/12/30/stochastic-optimization.html</link>
        <guid isPermaLink="true">http://larryfenn.com/research/2014/12/30/stochastic-optimization.html</guid>
        
        <category>stochastic-optimization</category>
        
        <category>optimization</category>
        
        <category>simulation</category>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Minima Finding</title>
        <description>&lt;p&gt;These are notes, originally written for a class I gave, about two line search methods for finding a minima in the deterministic context. I’m pretty happy about how the typesetting turned out, as it was my first foray into a “real” \(\TeX\) article.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/personal/minima/minimafinding.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 19 Jun 2014 02:02:03 -0400</pubDate>
        <link>http://larryfenn.com/personal/2014/06/19/minima.html</link>
        <guid isPermaLink="true">http://larryfenn.com/personal/2014/06/19/minima.html</guid>
        
        <category>optimization</category>
        
        
        <category>personal</category>
        
      </item>
    
  </channel>
</rss>
